{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 256\n",
    "WINDOW_LENGTH = 40\n",
    "WINDOW_STEP = 3\n",
    "BEAM_SIZE = 8\n",
    "NUM_LETTERS = 11\n",
    "MAX_LENGTH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the input file.\n",
    "INPUT_FILE_NAME = './Alice in Wonderland.txt'\n",
    "file = open(INPUT_FILE_NAME, 'r', encoding='utf-8')\n",
    "text = file.read()\n",
    "file.close()\n",
    "INPUT_FILE_NAME2 = './Frankenstein.txt'\n",
    "file = open(INPUT_FILE_NAME2, 'r', encoding='utf-8')\n",
    "text += file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "# Make lowercase and remove newline and extra spaces.\n",
    "text = text.lower()\n",
    "text = text.replace('\\n', ' ')\n",
    "text = text.replace('  ', ' ')\n",
    "# Encode characters as indices.\n",
    "unique_chars = list(set(text))\n",
    "char_to_index = dict((ch, index) for index, ch in enumerate(unique_chars))\n",
    "index_to_char = dict((index, ch) for index, ch in enumerate(unique_chars))\n",
    "encoding_width = len(char_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training examples.\n",
    "fragments = []\n",
    "targets = []\n",
    "for i in range(0, len(text) - WINDOW_LENGTH, WINDOW_STEP):\n",
    "    fragments.append(text[i: i + WINDOW_LENGTH])\n",
    "    targets.append(text[i + WINDOW_LENGTH])\n",
    "# Convert to one-hot encoded training data.\n",
    "X = np.zeros((len(fragments), WINDOW_LENGTH, encoding_width))\n",
    "y = np.zeros((len(fragments), encoding_width))\n",
    "for i, fragment in enumerate(fragments):\n",
    "    for j, char in enumerate(fragment):\n",
    "        X[i, j, char_to_index[char]] = 1\n",
    "    target_char = targets[i]\n",
    "    y[i, char_to_index[target_char]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "(40, 69)\n",
      "Training Input: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Training Output: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#Training Sample\n",
    "print(encoding_width)\n",
    "print(X[0].shape)\n",
    "print(\"Training Input:\",X[0])\n",
    "print(\"Training Output:\",y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, None, 126)         98784     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 126)         127512    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               392192    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 69)                17733     \n",
      "=================================================================\n",
      "Total params: 636,221\n",
      "Trainable params: 636,221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(126, \n",
    "                return_sequences=True,\n",
    "                dropout=0.2, recurrent_dropout=0.2,\n",
    "                input_shape=(None,encoding_width)\n",
    "                ))\n",
    "\n",
    "model.add(LSTM(126, \n",
    "                dropout=0.2,\n",
    "                return_sequences=True,\n",
    "                recurrent_dropout=0.2))\n",
    "\n",
    "model.add(LSTM(256, \n",
    "                dropout=0.2,\n",
    "                recurrent_dropout=0.2))\n",
    "\n",
    "model.add(Dense(encoding_width, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "                optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 190076 samples, validate on 10004 samples\n",
      "Epoch 1/100\n",
      "190076/190076 - 125s - loss: 2.7795 - val_loss: 2.4798\n",
      "Epoch 2/100\n",
      "190076/190076 - 141s - loss: 2.2751 - val_loss: 2.2586\n",
      "Epoch 3/100\n",
      "190076/190076 - 144s - loss: 2.1013 - val_loss: 2.0990\n",
      "Epoch 4/100\n",
      "190076/190076 - 143s - loss: 1.9893 - val_loss: 2.0044\n",
      "Epoch 5/100\n",
      "190076/190076 - 140s - loss: 1.9015 - val_loss: 1.9063\n",
      "Epoch 6/100\n",
      "190076/190076 - 143s - loss: 1.8348 - val_loss: 1.8484\n",
      "Epoch 7/100\n",
      "190076/190076 - 141s - loss: 1.7801 - val_loss: 1.7858\n",
      "Epoch 8/100\n",
      "190076/190076 - 141s - loss: 1.7337 - val_loss: 1.7457\n",
      "Epoch 9/100\n",
      "190076/190076 - 145s - loss: 1.6918 - val_loss: 1.6996\n",
      "Epoch 10/100\n",
      "190076/190076 - 145s - loss: 1.6599 - val_loss: 1.6703\n",
      "Epoch 11/100\n",
      "190076/190076 - 145s - loss: 1.6306 - val_loss: 1.6353\n",
      "Epoch 12/100\n",
      "190076/190076 - 143s - loss: 1.6034 - val_loss: 1.6165\n",
      "Epoch 13/100\n",
      "190076/190076 - 145s - loss: 1.5811 - val_loss: 1.5959\n",
      "Epoch 14/100\n",
      "190076/190076 - 144s - loss: 1.5612 - val_loss: 1.5723\n",
      "Epoch 15/100\n",
      "190076/190076 - 142s - loss: 1.5436 - val_loss: 1.5580\n",
      "Epoch 16/100\n",
      "190076/190076 - 142s - loss: 1.5277 - val_loss: 1.5407\n",
      "Epoch 17/100\n",
      "190076/190076 - 143s - loss: 1.5151 - val_loss: 1.5268\n",
      "Epoch 18/100\n",
      "190076/190076 - 143s - loss: 1.5016 - val_loss: 1.5165\n",
      "Epoch 19/100\n",
      "190076/190076 - 142s - loss: 1.4867 - val_loss: 1.5098\n",
      "Epoch 20/100\n",
      "190076/190076 - 142s - loss: 1.4740 - val_loss: 1.5040\n",
      "Epoch 21/100\n",
      "190076/190076 - 143s - loss: 1.4651 - val_loss: 1.4918\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16744\\2322147000.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                     shuffle=True)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 675\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3476\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y, validation_split=0.05,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS, verbose=2,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beam Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create initial single beam represented by triplet (probability , string , encoded string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BeamSearch(letters):\n",
    "    encoded = []\n",
    "    for i, char in enumerate(letters):\n",
    "        x = np.zeros(encoding_width)\n",
    "        x[ char_to_index[char]] = 1\n",
    "        encoded.append(x)\n",
    "    # encoded = np.array(encoded).reshape(len(encoded),1)\n",
    "    beams = [(np.log(1.0), letters, encoded)]\n",
    "    # Predict NUM_LETTERS into the future.\n",
    "    for i in range(NUM_LETTERS):\n",
    "        new_beams = []\n",
    "        minibatch = []\n",
    "        for triple in beams:\n",
    "            minibatch.append(triple[2])\n",
    "        y_predict = model.predict(np.array(minibatch), verbose=0)\n",
    "            # print(y_predict)\n",
    "\n",
    "        for j, softmax_vec in enumerate(y_predict):\n",
    "            triple = beams[j]\n",
    "            for k in range(BEAM_SIZE):\n",
    "                char_index = np.argmax(softmax_vec)\n",
    "                new_prob = triple[0] + np.log(softmax_vec[char_index])\n",
    "                new_letters = triple[1] + index_to_char[char_index]\n",
    "                x = np.zeros(encoding_width)\n",
    "                x[ char_index]  = 1\n",
    "                new_encoded = triple[2].copy()\n",
    "                new_encoded.append(x)\n",
    "                new_beams.append((new_prob, new_letters,new_encoded))\n",
    "                softmax_vec[char_index] = 0\n",
    "    # Prune tree to only keep BEAM_SIZE most probable beams.\n",
    "        new_beams.sort(key=lambda tup: tup[0], reverse=True)\n",
    "        beams = new_beams[0:BEAM_SIZE]\n",
    "    return beams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rabbit-hole she said alice, and the\n",
      "rabbit-hole she had been the works \n",
      "rabbit-hole she said alice, and she\n",
      "rabbit-hole she had been the words \n",
      "rabbit-hole she said alice, and thi\n",
      "rabbit-hole she said alice, and tha\n",
      "rabbit-hole she said alice, and i h\n",
      "rabbit-hole she had been the most o\n"
     ]
    }
   ],
   "source": [
    "NUM_LETTERS = 20\n",
    "letters = 'rabbit-hole she'\n",
    "beams = BeamSearch(letters)\n",
    "for item in beams:\n",
    "    print(item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "justine was discovered, and the \n",
      "justine was destruction of this \n",
      "justine was destruction of the s\n",
      "justine was destruction of the m\n",
      "justine was destruction of the p\n",
      "justine was discovered that i ha\n",
      "justine was destruction of the w\n",
      "justine was destruction of the c\n"
     ]
    }
   ],
   "source": [
    "letters = 'justine was '\n",
    "beams = BeamSearch(letters)\n",
    "for item in beams:\n",
    "    print(item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "direct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
